---
title: "Classifying Different Unilateral Dumbbell Bicep Curl Forms"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(caret)
set.seed(12345)
```

## Abstract
A dataset consisting of sensory readings collected from six males with ages between 20-28 years performing unilateral dumbbell bicep curls in five different ways was used to fit a model that can classify which of the five forms was being performed. The dataset was cleaned, split into training/testing sets, and pre-processed with principal component analysis before being fitted with a boosted trees model with the gbm method in caret. A 5-fold cross-validation scheme was performed to gauge the performance of the model. The final model was estimated to have an accuracy of about 75%.

## Exploratory Data Analysis and Cleaning
The dataset was composed of 19622 observations of 160 variables. An inspection of the data showed that around 6 of these variables were identification data, 1 was for time tracking, and 9 were filled with #DIV!/0 errors. These variables were discarded. The dataset was filled with NA values arising probably from the activity-dependent non-stimulation of sensors. These NA values were imputed with zeroes to prevent errors from the training functions.
```{r data_cleaning, warning = FALSE}
trainset <- read.csv("pml-training.csv")
trainset2 <- data.frame(apply(trainset, 2, function(x) as.numeric(as.character(x))))
trainset2[is.na(trainset2)] <- 0
trainset2 <- trainset2[7:159]
zeroes <- apply(trainset2, 2, sum)
trainset3 <- trainset2[,which(zeroes != 0)]
trainset3 <- cbind(trainset3, classe = trainset$classe)
```

##Fitting the Model
The dataset was split into a 70/30 training and testing set. With a large number of features available and limited computational power, a principal component analysis was performed to lower the dimensionality of the data. The pre-processing was instructed to capture 80% of the variance, reducing the number of features from 144 to 30. 

A boosted model with trees was chosen as a robust classification model. This was implemented through the caret gbm method with settings on default. A 5-fold cross-validation scheme was performed to gauge the accuracy of the model on unseen data. A k-fold cross-validation was chosen since it gives a relatively low bias estimate without too high a variance. A k=5 was chosen as this number is widely regarded as having an acceptable bias-variance tradeoff.
```{r model_fit}
inTrain <- createDataPartition(trainset3$classe, p = 0.7, list = FALSE)
training <- trainset3[inTrain,]
testing <- trainset3[-inTrain,]
modFit <- train(classe ~., data = training, method = "gbm", verbose = FALSE, preProcess = "pca",trControl = trainControl(method = "cv", number = 5, preProcOptions = list(thresh = 0.8)))
modFit
```

The model is estimated to have an accuracy of about 75%.

## Estimating Out-of-Sample Error
The model was applied to the testing set to estimate the out-of-sample error. A confusion matrix was applied to the model predictions and actual classifications.
```{r oos}
confusionMatrix(predict(modFit, testing), testing$classe)
```
Similar to the accuracy estimated from the 5-fold cross-validation, the model is expected to have an accuracy of about 75%.

## Conclusion
With the given dataset, it is possible to predict with acceptable accuracy the way in which a unilateral dumbbell bicep curl is performed. An accuracy of about 75% was achieved with a boosted trees model on data pre-processed with principal component analysis. A better accuracy may be achieved with other ensemble classification schemes and with more powerful computing equipment.